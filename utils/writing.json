[{
	"heading": "Computation",
	"content": "&emsp; Nowadays presidential elections are governed by computational data and software companies have to appear in front the U.S. congress to testify, because their actions are so immoral let alone simply breaking the law.<sup>1</sup> Nevertheless software's implications are not always that visible or represented in mass media. Most of the computation is happening behind the user interface, imbedded in integrated circuits consisting out of roughly 3 billion, 10 nanometer sized transistors.<sup>2</sup> But the occuring computation summoned by our everyday devices is at least as questionable to the same degree: Opaque self-reinforcing machine learning algorithms used by the local police validate themselves and become biased, YouTube videos for children are created algorithmically to maximize view counts and hype technologies consume more electricity than entire countries. Through computation humans achieved the power to create complex, unpredictable and injustice systems.",
	"notes": [{
		"author": "Matthew Rosenberg, Nicholas Confessore and Carole Cadwalladr",
		"title": "How Trump Consultants Exploited the Facebook Data of Millions",
		"page": 0,
		"link": "https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html"
	}, {
		"author": "Qualcomm",
		"title": "Snapdragon 835",
		"page": 0,
		"link": "https://www.qualcomm.com/products/snapdragon-835-mobile-platform"
	}]
}, {
	"heading": "Objectivity (of math)",
	"content": "&emsp; A big misunderstanding which occurs in the conversation about computation and which is a general thought by the general public is that computation has a privileged status of objectivity. Just like how philosophers and other academic fields humanism? conclude since a long time, objectivity doesn't really exist in the environment of human perception. From now on when objectivity is mentioned it is meant to play in these boundaries taken in consideration the non-objectivity of our world.<br>&emsp; It is important to remind ourselves again that computation is not objective. The argument is that software is based on the rational mathematics of computation. While mathematical expressions in themselves are objective, often the inputs used to calculate a specific problem, are generated and chosen by humans. <code>const r = Math.floor(Math.random() * 256)<br> const g = Math.floor(Math.random() * 256)<br> const b = Math.floor(Math.random() * 256)</code> Properties and objects are the two essential ways to describe a situation in formal computer code. Important is here that the objects and properties themselves can be objective. But interpolation or extrapolation are subjective, political actions."
}, {
	"heading": "Hermeneutics",
	"content": "&emsp; \"Hermeneutics\" introduced the concept of Gadamer's hermeneutic circle, arguing what we understand is directly linked to what we already know and what we already know derives from what we are able to understand.",
	"notes": [{
		"author": "Terry Winograd, Fernando Flores",
		"title": "Understanding Computers and Cognition: A New Foundation for Design",
		"page": 30,
		"link": "https://www.goodreads.com/book/show/53482.Understanding_Computers_and_Cognition"
	}]
}, {
	"heading": "Autopoiesis",
	"content": "&emsp; \"A plastic, structure-determined system (i.e., one whose structure can change over time while its identity remains) that is autopoietic will by necessity evolve in such a way that its activities are properly coupled to its medium. Its structure must change so that it generates appropriate changes of state triggered by specific perturbing changes in its medium; otherwise it will disintegrate.\"<sup>1</sup>",
	"notes": [{
		"author": "Terry Winograd, Fernando Flores",
		"title": "Understanding Computers and Cognition: A New Foundation for Design",
		"page": 45,
		"link": "https://www.goodreads.com/book/show/53482.Understanding_Computers_and_Cognition"
	}]
}, {
	"heading": "Representation—in",
	"content": "&emsp; \"Objectivity of math\" countered the misconception of objectivity in mathematical operations in software development. \"Hermeneutics\" argued that interpretation and understanding has to be contextualized. \"Autopoiesis\" introduced the main concept of the biologist Humberto Maturana looking at an organism and the environment as directly interacting entities creating each other and what he calls the fallacy of instructive interaction, questioning direct representation in the nervous system. Looking at these phenomena and the questions they deal with, it becomes apparent that they can be directly linked to software development. Representation becomes an essential part to continue the investigation of bias in computation.<br>&emsp; Cognitive representations are happening at every stage of writing software. Whether the program is about the prediction of where a next crime might happen or about displaying some semi-important tweets. It is the programmer who decides how and with what methods to program the software. And this practice is very subjective. Everytime the programmer thinks about implementing real world situations, it becomes a matter of choosing the \"right\" objects with their accompanied properties, so the program's veridicality and efficiency is maxed out. The programmer creates a formal representation of the external world. It is the programmers view on the world, with its (rational) traditions and prejudgements. This process is inevitable. And just like in Gadamer's hermeneutic circle, it is important to acknowledge it instead of committing the fallacy in believing the interpretation of the world can ever be free of all prejudice. Winograd and Flores call it the phenomenon of blindness: <blockquote>\"In writing a computer program, the programmer is responsible for characterizing the task domain as a collection of objects, properties, and operations, and for formulating the task as a structure of goals in terms of these. Obviously, this is not a matter of totally free choice. The programmer acts within a context of language, culture, and previous understanding, both shared and personal. The program is forever limited to working within the world determined by the programmer's explicit articulation of possible objects, properties, and relations among them. It therefore embodies the blindness that goes with this articulation.\"<sup>1</sup></blockquote> This form of cognitive representations is known and widely acknowledged in software studies, but what is often left out of the equation, while looking at the design of computer systems, is that there is another crucial representation happening at another part of the software development process.",
	"notes": [{
		"author": "Terry Winograd, Fernando Flores",
		"title": "Understanding Computers and Cognition: A New Foundation for Design",
		"page": 97,
		"link": "https://www.goodreads.com/book/show/53482.Understanding_Computers_and_Cognition"
	}]
}, {
	"heading": "Representation—out",
	"content": "&emsp; The representation process looked at until now is one directional, it occurs only in the direction of the computation, the external world is formalized into a symbol structure, in other words the representation is going towards the computation. The second main representation is taking place when the computation has to \"leave\" the program, to make use of it in the external world. So to say, the formalized has to be de/informalized.<br>&emsp; At this point of the process the field of design plays a considerable role. User interface-, user experience and interaction designer act on the same blindness as the programmer. Just like the program of the programmer, it’s the external world of the designer that is forever limited to working within the designer’s interface, experience or interaction. One major acknowledged type of algorithmic bias is the so called technical bias, which is formed by the technical design of the algorithm. A majority of this technical design are the interactions summoned by the designer.<br>&emsp; While the positions of the UI and UX designer got industrialized to a great extend — which also has positive outcomes: the necessity of computer science and design working together in front-end developing is increasing greatly — the field of the interaction designer still spares some hope in becoming a political representer. With interaction design’s interest in the socio-political environment of the occuring computation the proposition is: The interaction designer is the gatekeeper of our complex, unpredictable and injustice algorithmic biases."
}, {
	"heading": "Interaction",
	"content": "&emsp; I see the human-computer interaction designer as the gatekeeper of computation. Localization of interaction design in UI and UX design. To be clear, interaction design ≠ UX design. Interaction design looks at the environment and with that also at the socio-political implication the computation will have to other people, not just the user summoning the occuring computation. I would argue that the interaction designer is and should be a part of the traditional software development. Software development is becoming such an important and essential part of society, it needs a policing step in the send, a special position that governs the second translation stage, and specifically looks at the translation step towards the human. A step that sees the computation from the human perspective. A step that translates the computation back into \"human space\". Interdisciplinary analyses and creation, Intelligence, knowledge coming from action?"
}, {
	"heading": "Code/Space",
	"content": "&emsp; Im often referring to \"external\" physical world and the \"internal\" digital world. I'm not happy writing things like that. Might notice that I put quotionamarks around external. I would argue that these two worlds are not that easy distinguishable. But this is the second part of my research on the implications of software. I write like this to simply my way of thinking so it's understandable, where the programmer does what."
}, {
	"heading": "Models",
	"content": "&emsp; Close to the definition of the representation of computation models are abstract representation of a given process. And also models are opinions embedded in mathematics. Difference between models and representation: Models try to find pattern, Models are focused on a process not situation, models are predicting something. In the end of the day, the biggest factor of a working model, is the dataset that was used to train and validate the model. One obvious but nevertheless important thing to notice: This data can only come from the past and the mere existence of the model, expects that the pattern found in the data will occur again. Models are based on the past. <code>  const hidden = tf.layers.dense({ <br>&ensp; units: 16, <br>&ensp; activation: 'sigmoid', <br>&ensp; inputShape: [3] <br> })</code>Models can become the truth, the reality, “the de facto law of the land”, the status-quo. They create their own realities, because people take them like they represent the truth perfectly."
}, {
	"heading": "Self-reinforcement",
	"content": "&emsp; One of the most dangerous parts of an machine learning model is that it can validate itself. Partly because the predictions/outputs of these algorithms are seen as a \"truth\"-state, people will take these for granted/will follow the outcomes. If you take the example of the predictive policing field. The police officer actually checks the location where the crime rate is higher. While patrolling this area more, he will see more, most probably small crimes, happen there and think this is what the machine predicted. The model running on the servers of the police, will get the new data input to use for training. While training the model will validate itself with its self-serving definition of success: The prediction from the last batch was right, the crime happened there and the model arranges its weights to give that specific location a higher chance to activate. The model created its own distorted view of reality.<sup>1</sup> I say distorted here because of course the reality is now that a new crime happened, but it would have never been marked it, if the model wouldn't have predicted it. Clarify the difference between a actual crime and a fallacy crime only being marked because of automation bias. The model weights the variable of that area from now on stronger than before. Just the mere concept of using historical crime data from the past (racist, sexist history) to predict crime locations from the future, is a vicious feedback loop. Just the fact to see the past and future based on the same information is fatal.",
	"notes": [{
		"author": "Apprich, Chun, Cramer, Steyerl",
		"title": "Pattern Discrimination",
		"page": 33,
		"link": "https://meson.press/books/pattern-discrimination/"
	}]
}, {
	"heading": "Same data",
	"content": "&emsp; Time, how data analyses went from past-present to past-future Looking at how machine learning algorithms work and that the datasets used to train them are the main definition of the outputs. The question of a closer examination of the data is required. Because we can only have access to data that was generated in the past, the mere concept of machine learning, assumes that the data of the past is the same data from the future. A closer look at the history of humans reveals a lot of what is seen as problematic with the algorithms. Our history is racist. No wonder the data collected from it generates racist algorithms. <code class='json'>{<br>&ensp; \"data\": {<br>&ensp;&ensp; \"label\": \"violet\",<br>&ensp;&ensp; \"color\": {<br>&ensp;&ensp;&ensp; \"r\": 201,<br>&ensp;&ensp;&ensp; \"g\": 139,<br>&ensp;&ensp;&ensp; \"b\": 214<br>&ensp;&ensp;&ensp;}<br>&ensp;&ensp;},<br>&ensp; \"client\": \"d7ca0601525ba\",<br>&ensp; \"timestamp\": 1546008439124,<br>&ensp; \"_id\": \"1ROBWPmQort0K4wv\"<br>}</code> \"If you want a vision of the future, imagine the past (artificially) extended forever\"<sup>1</sup>",
	"notes": [{
		"author": "Karen Eliot aka. Monty Cantsin",
		"title": "ANTI-POST-ACTUALISM++++++",
		"page": 0,
		"link": "https://www.thing.de/projekte/7:9%23/berndt_smile7_actualism.html"
	}]
}, {
	"heading": "Classifying a spectrum",
	"content": "&emsp; Classification is a standard procedure in the data science field. A classification algorithm can allocate given inputs to before specified classes. It is the basic action of categorization a variety of input data. While there are a lot of cases where classification makes sense to a specific degree. In most of the cases where human beings are directly affected not the right term, more personal, subjective things; give example of more clear parameters classification becomes difficult. I call it the classification of a spectrum. In a spectrum there are no clear references or categories. It varies from what background/perspective the spectrum is looked at. It becomes rather dangerous to generalize the categories of a spectrum. Because of the scale a machine learning algorithm can have, it will only work for the environment the programmer was in at the time of defining the classes/labels. It could have severe consequences to look at a individual classification of a spectrum as a universal truth or settlement. In the example of Cathy O'Neil's college, university ranking,<sup>1</sup> how would be “educational excellence” defined? It would vary strongly on the personal preferences. It is a common mistake in data science to take a chosen property or object as given. It is a much bigger challenge to quantify or measure a spectrum. Most of the time the spectrum does not fit the language of a model. It can't be easily “normalized”. Nevertheless these variables exist in models, although they are just an extrapolation from other given values: proxies are created. Spectrum aka. Fundamental fluidity of Identity.",
	"notes": [{
		"author": "Cathy O'Neil",
		"title": "Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy",
		"page": 50,
		"link": "https://mathbabe.org/"
	}]
}, {
	"heading": "Proxies",
	"content": "&emsp; Often when a variable cannot be directly quantified or be measured. Other data points are looked at and the needed variable will be replaced by a so called proxy variable. Yes, as you could guess from the flow of this writing, proxies are the point where a classification can go horribly wrong. The main problem with proxies is that their definition is based on other variables, they don't have a ground themselves they can stand on. The other problem is that they are actually a direct product out of human bias, being defined even before they are fed into the model. Often they are a direct replacement of the actual wanted variable.<sup>1</sup> Not enough data could be gathered for the wanted variable, so they are extrapolated by others to form this new definition. Later in the process of evaluating the model or updating it. The proxy variables are hard to spot and redefine, since they shape the very definition of the models purpose. Proxies embody the pre assumptions of their creator. Another big problem with proxies is that they are a kind of shortcut for the complex reality and this shortcut can, if known, be exploited way easier than it would be to exploit some real variable of the algorithm. The proxies invite a potential exploitation to a great extend. Just like the creators of the model used the proxy as a shortcut to interpolate a situation. This bypass can be used to trick the algorithm into predicting specific things.",
	"notes": [{
		"author": "Cathy O'Neil",
		"title": "Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy",
		"page": 59,
		"link": "https://mathbabe.org/"
	}]
}, {
	"heading": "Missing variables",
	"content": "&emsp; The story of the missing variable is an important one. Like in design, taking away and deciding not to include something, is a political action. It has great consequences what is left out of a concept. It is important to look for the variables that were not included in the training of a model. Often the missing variable can be one of great significance. Although it is not imbedded in the model itself. The missing variable nevertheless is part of the model in the real world. So the model WILL have implications on it. And most of the times it is exactly that property, which was chosen to be left out of the equation, that changes the most because of the models implications on the real world. Example of tuition fee in university-ranking.<sup>1</sup>",
	"notes": [{
		"author": "Apprich, Chun, Cramer, Steyerl",
		"title": "Pattern Discrimination",
		"page": 33,
		"link": "https://meson.press/books/pattern-discrimination/"
	}]
}, {
	"heading": "Single source of truth",
	"content": "&emsp; Digital services are looked at as a single source of truth.<sup>1</sup> When did you walk the last time and listened to your gut feeling instead of following the blue route? But then what where is this truth coming from? The model behind the app? It sees pattern that we didn't see, the have to exist! They are real. But wait? What data was used to train the model? Oh, I see some completely false filled out bureaucracy forms. Cool.",
	"notes": [{
		"author": "Apprich, Chun, Cramer, Steyerl",
		"title": "Pattern Discrimination",
		"page": 7,
		"link": "https://meson.press/books/pattern-discrimination/"
	}]
}, {
	"heading": "Inscription of subjectivity",
	"content": "&emsp; Describe and analyze the constant subjective decisions that occured while creating the machine learning code."
}]